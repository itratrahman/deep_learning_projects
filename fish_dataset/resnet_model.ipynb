{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.layers import Input, Conv2D, ELU, BatchNormalization,concatenate, \\\n",
    "                                    Add, GlobalAveragePooling2D, Flatten, Dense, MaxPooling2D\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radom_seed = 0\n",
    "random.seed(radom_seed)\n",
    "numpy_seed = 0\n",
    "np.random.seed(numpy_seed)\n",
    "tensorflow_seed = 0\n",
    "set_seed(tensorflow_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, N_CLASSES = 512,512,3,9\n",
    "BASE_DIR = os.path.abspath(os.path.dirname(\"__file__\"))\n",
    "INPUT_DIR = os.path.join(BASE_DIR, \"data\", \"NA_Fish_Dataset\")\n",
    "SAVE_DIRECTORY = os.path.join(BASE_DIR, \"data\", \"numpy_data\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"model_files\")\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_labels = dict(zip(list(os.walk(INPUT_DIR))[0][1], [i for i in range(10)]))\n",
    "labels_to_classes = dict(zip([i for i in range(10)], list(os.walk(INPUT_DIR))[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(SAVE_DIRECTORY, \"X_train.npy\"))\n",
    "X_valid = np.load(os.path.join(SAVE_DIRECTORY, \"X_valid.npy\"))\n",
    "Y_train = np.load(os.path.join(SAVE_DIRECTORY, \"Y_train.npy\"))\n",
    "Y_valid = np.load(os.path.join(SAVE_DIRECTORY, \"Y_valid.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (30.0, 20.0)\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.title(labels_to_classes[Y_valid[i]])\n",
    "    plt.imshow(X_valid[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (30.0, 20.0)\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.title(labels_to_classes[Y_train[i]])\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu_bn(x):\n",
    "    \"\"\"\n",
    "    A function for computing elu then batch normalization\n",
    "    x - input tensor\n",
    "    bn - ouput tensor after elu and bn\n",
    "    \"\"\"\n",
    "    elu = ELU()(x)\n",
    "    bn = BatchNormalization()(elu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x, num_filters, kernel_size):\n",
    "    \"\"\"\n",
    "    A function to create residual block\n",
    "    x - input tensor\n",
    "    num_filters - number of filters\n",
    "    kernel_size - size of kernel\n",
    "    out - output tensor\n",
    "    \"\"\"\n",
    "    x2 = Conv2D(kernel_size=kernel_size,\n",
    "               strides= 1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(x)\n",
    "    x2 = elu_bn(x2)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides= 1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(x2)\n",
    "    y = elu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(y)\n",
    "    out = Add()([x2, y])\n",
    "    out = elu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_net(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, N_CLASSES,\n",
    "               filters, kernels, learning_rate):\n",
    "    \"\"\"\n",
    "    A function to create resnet\n",
    "    filters - list containing filter size at successive conv layer\n",
    "    kernels - list containing kernel size at successive conv layer\n",
    "    model - keras model object\n",
    "    \"\"\"\n",
    "    X = Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    n_layers = len(kernels)\n",
    "    for i in range(n_layers):\n",
    "        if i ==0:\n",
    "            layer = residual_block(X, filters[i], kernels[i])\n",
    "            layer = MaxPooling2D((2,2), strides=(2,2), padding='same')(layer)\n",
    "        elif i == n_layers-1:\n",
    "            layer = residual_block(layer, filters[i], kernels[i])\n",
    "        else:\n",
    "            layer = residual_block(layer, filters[i], kernels[i])\n",
    "            layer = MaxPooling2D((2,2), strides=(2,2), padding='same')(layer)\n",
    "\n",
    "    Y = GlobalAveragePooling2D()(layer)\n",
    "    Y = Dense(128, activation='elu')(Y)\n",
    "    Y = BatchNormalization()(Y)\n",
    "    Y = Dense(N_CLASSES, activation='softmax')(Y)\n",
    "\n",
    "    model = Model(inputs=X, outputs=Y)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n",
    "num_filters = 64\n",
    "kernels = [3,3,3,3]\n",
    "filters = [16,16,32,32]\n",
    "learning_rate = (1e-3)*0.25\n",
    "model = create_net(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, N_CLASSES,\n",
    "                   filters, kernels, learning_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, batch_size, checkpoint_cb, \n",
    "                X_train, Y_train, X_valid, Y_valid):\n",
    "    history = model.fit(X_train, Y_train, epochs=epochs, batch_size = batch_size,\n",
    "                        validation_data = (X_valid, Y_valid), \n",
    "                        callbacks=[checkpoint_cb])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "checkpoint_cb = ModelCheckpoint(MODEL_PATH, monitor = 'val_accuracy', \n",
    "                                save_freq = \"epoch\", save_best_only=True, \n",
    "                                mode = \"max\")\n",
    "model, history = train_model(model, epochs, batch_size, checkpoint_cb, \n",
    "                             X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss,  label='Training Loss', linewidth = 10.0)\n",
    "plt.plot(epochs, val_loss,  label='Validation Loss', linewidth = 3)\n",
    "plt.title('Loss vs Epochs', fontsize = 25)\n",
    "plt.xlabel('Epochs', fontsize = 15)\n",
    "plt.ylabel('Loss', fontsize = 15)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc,  label='Training Accuracy', linewidth = 10.0)\n",
    "plt.plot(epochs, val_acc,  label='Validation Accuracy', linewidth = 3)\n",
    "plt.title('Accuracy vs Epochs', fontsize = 25)\n",
    "plt.xlabel('Epochs', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontsize = 15)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(MODEL_PATH)\n",
    "valid_accuracy = round(accuracy_score(Y_valid, np.argmax(model.predict(X_valid), axis = -1)),2)\n",
    "print(\"Valid accuracy:\",valid_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
